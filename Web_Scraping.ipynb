{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "southern-lesson",
   "metadata": {},
   "source": [
    "# Exercise 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-marine",
   "metadata": {},
   "source": [
    "1. Scrape the information of all lawn mowers from https://www.productreview.com.au/c/lawn-mowers. For this question, you only need to obtain the results on the first page. For each mower, you need to extract its name, rating, price and the URL of its image. Save them as four lists called **products**, **ratings**, **prices** and **imageURLs**. Then save these four lists as one four-column data frame called **df**. Name the columns as way you like. \n",
    "\n",
    "    If your solution is correct, you should obtain exactly 20 products on this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-customs",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Your answer here:\n",
    " \n",
    "#Check your answer\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0e8432",
   "metadata": {},
   "source": [
    "If you are curious about how to download the images with the URLs, try the command below. It downloads the first image in your **df** and have it as 'image0.jpg'. It is not hard to download all images using a for loop. Since processing images data is not our focus, we will skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fbbc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = requests.get(df[\"imageURLs\"][0]).content\n",
    "with open('image0.jpg', 'wb') as handler:\n",
    "    handler.write(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-lesson",
   "metadata": {},
   "source": [
    "2. Repeat question 1, but this time you must scrape the information of mowers on the first five pages from https://www.productreview.com.au/c/lawn-mowers. For each mower, you need to extract its name, rating, and the URL of its image. (Price is not needed this time because some mowers do not have a price, which makes thing complicated.) Save them as three lists called **products_all**, **ratings_all** and **imageURLs_all**. Then save these three lists as one three-column data frame called **df_all**. Name the columns as way you like. \n",
    "\n",
    "    *Hint: The URL of each page has three segments. For example, the second page is https://www.productreview.com.au/c/lawn-mowers?page=2#search-results You can create this URL by concatenating the following three segements:*\n",
    "         https://www.productreview.com.au/c/lawn-mowers?page=\n",
    "         \n",
    "         2\n",
    "         \n",
    "         #search-results\n",
    "         \n",
    "      Only the second segement changes with the for-loop. Don't forget to pause for 1~2 seconds between pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-attachment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Your answer here:\n",
    "\n",
    "#Check your answer\n",
    "df_all.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
