{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "036088e5",
   "metadata": {},
   "source": [
    "# Exercise 7 Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398ac794",
   "metadata": {},
   "source": [
    "The csv file \"classdata/BA_news_return.csv\" contains the headlines of the news about The Boeing Company published by Thomson Reuters each day in 2020. See column **headline**. It also contains the stock return of Boeing one day after the news being published. See column **nextday_RET**. Note that there can be multiple news on Boeing published on the same day.  If so, the **headline** field will contain the headlines of all news on that day. (They are concatenated into one string.). Your task is to identify the main topics in each day's healines using a LDA model. \n",
    "\n",
    "The following code reads the data into **df**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b3911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"classdata/BA_news_return.csv\")\n",
    "df[\"headline\"]=df[\"headline\"].str.replace(\"737 MAX\", \"737MAX\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4292ecbd",
   "metadata": {},
   "source": [
    "1. Create a DTM for column \"headline\" based on the following requirements:\n",
    "\n",
    "    - Use the default tokenizer from sklearn library. \n",
    "    - Add \"boeing\" and \"says\" to the stop word list of nltk and then remove stop words. \n",
    "    - Stem the tokens using the SnowBall stemmer from nltk. \n",
    "    - Create DTM with TF score and unigram.\n",
    "\n",
    "Print the shape of your DTM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9006c6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You answer here:\n",
    "\n",
    "#Check your answer\n",
    "DTM.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9fc1ee",
   "metadata": {},
   "source": [
    "2.a Plot the perplexity score against the number of topics of a LDA model built on the DTM from question 1. You need to plot the numbers of topics from 6 to 15. Set the parameters of your LDA model as follows:\n",
    "\n",
    " - n_jobs=-1\n",
    " - max_iter=50\n",
    " - random_state=2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d281f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You answer here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f701b289",
   "metadata": {},
   "source": [
    "2.b According to the plot in question 2.a, use the Elbow method to determine the number of topics of the LDA model. Build the LDA model using the DTM from question 1. Set the parameters of your LDA vectorizer as follows:\n",
    "\n",
    " - n_jobs=-1\n",
    " - max_iter=50\n",
    " - random_state=2021\n",
    " \n",
    "Save your LDA model as a variable called **lda** and print the perplexity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4212c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You answer here:\n",
    "\n",
    "#Check your answer\n",
    "lda.perplexity(DTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cc61f0",
   "metadata": {},
   "source": [
    "3. Create the term-topic matrix for the LDA model you created in question 2.b. Save term-topic matrix as a data frame called **TTopicM**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4df169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You answer here:\n",
    "    \n",
    "#Check your answer\n",
    "TTopicM.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7486b544",
   "metadata": {},
   "source": [
    "4. Based on the term-topic matrix in question 3, identify the ten most likely words under each topic and save them as columns in a data frame called **TermOfTopic**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba854b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#You answer here:\n",
    "    \n",
    "#Check your answer\n",
    "TermOfTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f3ea53",
   "metadata": {},
   "source": [
    "5. Create the document-topic matrix and save it as a data frame called **DTopicM**. Create a new data frame called **dfnew** by concatinating **df** and **DTopicM** horizontally (i.e., axis=1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc39f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your answer here:\n",
    " \n",
    "#Chek your answer\n",
    "dfnew.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b60f1bf",
   "metadata": {},
   "source": [
    "6. Run the following code the generate the correlation between the stock returns and the topic scores. Which topic is most negatively correlated with the stock return of Boeing. Use a few words to describe this topic. Similary, which topic is most positively correlated with the stock return. Use a few words to describe this topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e1d1c8",
   "metadata": {},
   "source": [
    "**Your answer here:**\n",
    "\n",
    "The most negative topic: southwest, faa\n",
    "\n",
    "The most positive topic: Spirit AeroSystems, embraer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c0889e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This code calculates the correlation between any two numeric columns in the data frame\n",
    "dfnew.corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
